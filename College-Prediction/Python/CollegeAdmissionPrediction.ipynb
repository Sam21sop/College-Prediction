{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNJ2yMlwC6F+sS8/v+/8oBM"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Data Collection"
      ],
      "metadata": {
        "id": "m8QeRbxzAaxc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tabula-py\n"
      ],
      "metadata": {
        "id": "65lhdCdyNB2O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip freeze"
      ],
      "metadata": {
        "id": "gli6YAGkOvwU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "Pdrv4Ns1AGLw"
      },
      "outputs": [],
      "source": [
        "# prompt: To convert PDF files to CSV files in Python, you can use the tabula-py library for extracting tables from PDFs and the pandas library for working with dataframes.\n",
        "\n",
        "import tabula\n",
        "import pandas as pd\n",
        "\n",
        "# Load the PDF file\n",
        "pdf_file = '/content/1.pdf'\n",
        "\n",
        "# Extract tables from the PDF\n",
        "tables = tabula.read_pdf(pdf_file, pages='all')\n",
        "\n",
        "# Convert the tables to pandas dataframes\n",
        "df = pd.concat(tables)\n",
        "\n",
        "# Save the dataframe to a CSV file\n",
        "df.to_csv('output.csv', index=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "from tabula import read_pdf\n",
        "\n",
        "def convert_pdf_to_csv(pdf_path, csv_path):\n",
        "    # Use tabula to extract tables from the PDF\n",
        "    tables = read_pdf(pdf_path, pages='all', multiple_tables=True)\n",
        "\n",
        "    # Assuming you want to save all tables from the PDF into a single CSV file\n",
        "    combined_df = pd.concat(tables, ignore_index=False)\n",
        "\n",
        "    # Save the combined dataframe to a CSV file\n",
        "    combined_df.to_csv(csv_path, index=False)\n",
        "    print(f\"Converted: {pdf_path} to {csv_path}\")\n",
        "\n",
        "def convert_all_pdfs_to_csv(folder_path):\n",
        "    # List all files in the folder\n",
        "    files = os.listdir(folder_path)\n",
        "\n",
        "    # Iterate through each file\n",
        "    for file in files:\n",
        "        if file.endswith('.pdf'):\n",
        "            # Construct the full paths for the PDF and CSV files\n",
        "            pdf_path = os.path.join(folder_path, file)\n",
        "            csv_name = os.path.splitext(file)[0] + '.csv'\n",
        "            csv_path = os.path.join(folder_path, csv_name)\n",
        "\n",
        "            # Convert the PDF to CSV\n",
        "            convert_pdf_to_csv(pdf_path, csv_path)\n",
        "\n",
        "# Specify the folder path containing the PDF files\n",
        "folder_path = '/content/sample_data/PDF'\n",
        "\n",
        "# Call the function to convert all PDF files to CSV in the folder\n",
        "convert_all_pdfs_to_csv(folder_path)\n"
      ],
      "metadata": {
        "id": "3Oh1tQpANq-y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: To concatenate all CSV files into a single CSV file in Python\n",
        "\n",
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "# Specify the folder path containing the CSV files\n",
        "folder_path = '/content/sample_data/CSV'\n",
        "\n",
        "# List all CSV files in the folder\n",
        "files = os.listdir(folder_path)\n",
        "\n",
        "# Create an empty DataFrame\n",
        "df = pd.DataFrame()\n",
        "\n",
        "# Iterate through each CSV file\n",
        "for file in files:\n",
        "    # Read the CSV file into a DataFrame\n",
        "    df_temp = pd.read_csv(os.path.join(folder_path, file))\n",
        "\n",
        "    # Concatenate the DataFrame with the empty DataFrame\n",
        "    df = pd.concat([df, df_temp], ignore_index=True)\n",
        "\n",
        "# Save the concatenated DataFrame to a new CSV file\n",
        "df.to_csv('output.csv', index=False)\n"
      ],
      "metadata": {
        "id": "28qmw0q3RdMj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "\n",
        "def concatenate_csv_files(folder_path, output_csv):\n",
        "    # List all files in the folder\n",
        "    files = os.listdir(folder_path)\n",
        "\n",
        "    # Initialize an empty DataFrame to store the combined data\n",
        "    combined_df = pd.DataFrame()\n",
        "\n",
        "    # Iterate through each file\n",
        "    for file in files:\n",
        "        if file.endswith('.csv'):\n",
        "            # Construct the full path for the CSV file\n",
        "            csv_path = os.path.join(folder_path, file)\n",
        "\n",
        "            # Read the CSV file into a DataFrame\n",
        "            df = pd.read_csv(csv_path)\n",
        "\n",
        "            # Concatenate the DataFrame to the combined DataFrame\n",
        "            combined_df = pd.concat([combined_df, df], ignore_index=True)\n",
        "\n",
        "    # Save the combined DataFrame to a single CSV file\n",
        "    combined_df.to_csv(output_csv, index=False)\n",
        "    print(f\"Combined all CSV files into: {output_csv}\")\n",
        "\n",
        "# Specify the folder path containing the CSV files\n",
        "folder_path = '/content/sample_data/CSV'\n",
        "\n",
        "# Specify the output CSV file\n",
        "output_csv = 'output_combined.csv'\n",
        "\n",
        "# Call the function to concatenate all CSV files into a single CSV file\n",
        "concatenate_csv_files(folder_path, output_csv)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IF66afmJThQK",
        "outputId": "c6a09ec5-3350-4972-a057-7a2c2f020c19"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Combined all CSV files into: output_combined.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "\n",
        "def add_table_heading(csv_path):\n",
        "    # Read the CSV file into a DataFrame\n",
        "    df = pd.read_csv(csv_path)\n",
        "\n",
        "    # Check if the required columns are already present\n",
        "    required_columns = [\"sr_no\", \"College_name\", \"cutoff\"]\n",
        "    missing_columns = set(required_columns) - set(df.columns)\n",
        "\n",
        "    # Add missing columns with NaN values\n",
        "    for column in missing_columns:\n",
        "        df[column] = float('nan')\n",
        "\n",
        "    # Save the updated DataFrame back to the CSV file\n",
        "    df.to_csv(csv_path, index=False)\n",
        "\n",
        "def concatenate_csv_files(folder_path, output_csv):\n",
        "    # List all files in the folder\n",
        "    files = os.listdir(folder_path)\n",
        "\n",
        "    # Initialize an empty DataFrame to store the combined data\n",
        "    combined_df = pd.DataFrame()\n",
        "\n",
        "    # Iterate through each file\n",
        "    for file in files:\n",
        "        if file.endswith('.csv'):\n",
        "            # Construct the full path for the CSV file\n",
        "            csv_path = os.path.join(folder_path, file)\n",
        "\n",
        "            # Add table heading/features to each CSV file\n",
        "            add_table_heading(csv_path)\n",
        "\n",
        "            # Read the CSV file into a DataFrame\n",
        "            df = pd.read_csv(csv_path)\n",
        "\n",
        "            # Concatenate the DataFrame to the combined DataFrame\n",
        "            combined_df = pd.concat([combined_df, df], ignore_index=True)\n",
        "\n",
        "    # Save the combined DataFrame to a single CSV file\n",
        "    combined_df.to_csv(output_csv, index=False)\n",
        "    print(f\"Combined all CSV files into: {output_csv}\")\n",
        "\n",
        "# Specify the folder path containing the CSV files\n",
        "folder_path = '/content/sample_data/CSV'\n",
        "\n",
        "# Specify the output CSV file\n",
        "output_csv = 'output_combined.csv'\n",
        "\n",
        "# Call the function to concatenate all CSV files into a single CSV file\n",
        "concatenate_csv_files(folder_path, output_csv)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lA8LAjn5TxIv",
        "outputId": "8d0dba89-2595-4c72-8e6a-ca41eeb409e2"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Combined all CSV files into: output_combined.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "8wVX3b6OUpLe"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}